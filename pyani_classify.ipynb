{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification with `pyani` output\n",
    "\n",
    "This notebook contains experiments in generating *continuous* classifications from `pyani` output. The general principle is as follows:\n",
    "\n",
    "1. Generate a graph with each isolate as a node, whose edges contain information about %identity and %coverage for the pairwise comparison between genomes\n",
    "2. Prune the graph by removing edges that fall below a minimum level of %coverage.\n",
    "3. Identify all (*k*-complete) graphs at this level, and note the minimum %identity *i*\n",
    "\n",
    "Then, for each of the initial graphs:\n",
    "\n",
    "* Progressively prune the graph edges, from lowest to highest %identity.\n",
    "* When a *k*-complete graph is noted, we record this as a specific grouping/classification as $G_{m,n}$ where $m$ is the %coverage used to construct the initial graph, and $n$ is the %identity at which the $k$-complete graph is first observed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing the algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Python dependencies\n",
    "\n",
    "We're using `networkx` for the graph manipulations, and `pygraphviz` for some rendering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pylab inline\n",
    "\n",
    "import csv\n",
    "import os\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial Graph construction\n",
    "\n",
    "Load the coverage and identity data as `Pandas` dataframes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Data from a Buchnera comparison\n",
    "#covfile = \"Buchnera_ANIm/ANIm_alignment_coverage.tab\"\n",
    "#idfile = \"Buchnera_ANIm/ANIm_percentage_identity.tab\"\n",
    "\n",
    "# Data from an Alcanivorax comparison\n",
    "#covfile = \"tests/Alcanivorax_ANIm/ANIm_alignment_coverage.tab\"\n",
    "#idfile = \"tests/Alcanivorax_ANIm/ANIm_percentage_identity.tab\"\n",
    "#labels = \"tests/Alcanivorax/labels.txt\"\n",
    "\n",
    "# Data from SRE comparison\n",
    "indir = \"tests/SRE\"\n",
    "prefix = \"SRE\"\n",
    "\n",
    "# Data from Streptomyces comparison\n",
    "#indir = \"tests/Streptomyces\"\n",
    "#prefix = \"Strep\"\n",
    "\n",
    "# Define filesnames\n",
    "covfile = os.path.join(indir, \"ANIm_alignment_coverage.tab\")\n",
    "idfile = os.path.join(indir, \"ANIm_percentage_identity.tab\")\n",
    "labels = os.path.join(indir, \"labels.txt\")\n",
    "classes = os.path.join(indir, \"classes.txt\")\n",
    "\n",
    "# Load pyani outputs into dataframes\n",
    "covdata = pd.DataFrame.from_csv(covfile, sep='\\t')\n",
    "iddata = pd.DataFrame.from_csv(idfile, sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create nodes and edges for an undirected graph with the *minimal* coverage (identity should be the same in both directions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Our node names will be the isolate labels\n",
    "node_names = covdata.columns\n",
    "\n",
    "# Load labels for isolates\n",
    "with open(labels, mode='r') as fh:\n",
    "    reader = csv.reader(fh, delimiter='\\t')\n",
    "    labeldict = {rows[0]:rows[1] for rows in reader\n",
    "                 if rows[0] in node_names}\n",
    "\n",
    "# Load classes for isolates\n",
    "with open(classes, mode='r') as fh:\n",
    "    reader = csv.reader(fh, delimiter='\\t')\n",
    "    classdict = {rows[0]:rows[1] for rows in reader\n",
    "                 if rows[0] in node_names}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Loop over each isolate ID and get all coverage/identity values\n",
    "rows_list = []\n",
    "for idx, node_from in enumerate(node_names[:-1]):\n",
    "    for node_to in node_names[idx+1:]:\n",
    "        datadict = {'from': node_from,\n",
    "                    'to': node_to,\n",
    "                    'coverage': min(covdata[node_from][node_to],\n",
    "                                    covdata[node_to][node_from]),\n",
    "                    'identity': iddata[node_from][node_to]}\n",
    "        rows_list.append(datadict)\n",
    "\n",
    "# Create dataframe of from/to nodes, coverage and identity (in that order)\n",
    "node_data = pd.DataFrame(rows_list, columns=['from', 'to', 'coverage', 'identity'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build a `networkx` undirected graph from this data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create graph\n",
    "G = nx.Graph()\n",
    "\n",
    "# Function to add an edge to the graph\n",
    "def add_edge(row, graph, cov_thresh=0.5):\n",
    "    if row['coverage'] >= cov_thresh:\n",
    "        graph.add_edge(row['from'], row['to'],\n",
    "                       coverage=row['coverage'],\n",
    "                       identity=row['identity'],\n",
    "                       difference=1-row['identity'],\n",
    "                       logident=abs(log(row['identity'])))\n",
    "\n",
    "# Add nodes, then loop over rows in node data, adding edges\n",
    "for node in node_names:\n",
    "    G.add_node(node)\n",
    "\n",
    "errs = node_data.apply(add_edge, axis=1, args=(G,), cov_thresh=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rendering graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualising the graph with `pylab`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig = figure(figsize=(10,10))  # NetworkX respects the current pylab figure/axes\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "# k determines the distance between nodes, iterations controls rounds of layout\n",
    "layout = nx.spring_layout(G, weight='identity', k=0.1, iterations=200)\n",
    "nx.draw(G, pos=layout, ax=ax)\n",
    "outfname = \"/Users/lpritc/Desktop/{0}_ANIm_graph.pdf\".format(prefix)\n",
    "savefig(outfname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save graph \n",
    "nx.write_gml(G, 'sre_anim_graph.gml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualising, and labelling the nodes using a dictionary, testing a number of layout options:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig = figure(figsize=(20,20))\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "\n",
    "# Try different weightings\n",
    "weight = 'identity'\n",
    "#weight = 'logident'\n",
    "#weight = 'difference'\n",
    "\n",
    "# Try different layouts\n",
    "layout = nx.spring_layout(G, weight=weight, k=0.125, iterations=800)\n",
    "#layout = nx.circular_layout(G)\n",
    "#layout = nx.random_layout(G)\n",
    "#layout = nx.shell_layout(G)\n",
    "#layout = nx.spectral_layout(G, weight=weight, scale=2)\n",
    "\n",
    "# Render\n",
    "nx.draw(G, pos=layout, ax=ax, with_labels=True, labels=labeldict,\n",
    "        alpha=0.4, font_size=10, edge_color=\"#cccccc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions to draw networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def draw_network(graph, weight='identity', k=0.125, iterations=800, figsize=(20, 20)):\n",
    "    fig, ax = subplots(figsize=figsize)\n",
    "    layout = nx.spring_layout(graph, weight=weight, k=k, iterations=iterations)\n",
    "    labels = {key: val for (key, val) in labeldict.items() if key in graph.nodes()}\n",
    "    nx.draw(graph, pos=layout, ax=ax, with_labels=True, labels=labels,\n",
    "            alpha=0.4, font_size=10, edge_color=\"#cccccc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identifying natural groupings of isolates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By looking at the sizes of the connected component subgraphs (i.e. the individual disjoint graphs in the network) we can see how many different 'broad' classifications are supported by the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for SG in nx.connected_component_subgraphs(G):\n",
    "    print(\"{0}\\n{1}\\n\\n\".format(len(SG.nodes()),\n",
    "                                [labeldict[n] if n in labeldict else n\n",
    "                                 for n in SG.nodes_iter()]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Cliques* are completely-connected subgraphs, and represent internal groupings of isolates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cliques = list(nx.find_cliques(G))\n",
    "for c in cliques:\n",
    "    print(\"{0}\\n{1}\\n\\n\".format(len(c),\n",
    "                                [labeldict[n] if n in labeldict else n\n",
    "                                 for n in c]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the total size of the cliques is equal to the total number of nodes in the network, then we have a self-consistent classification of isolates into mutually-supporting groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Network size: {0}, Number of cliques: {1}, Total clique size: {2}\".format(len(G),\n",
    "                                                                                 len(cliques),\n",
    "                                                                                 sum([len(c) for c in cliques])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is possible that one or more nodes may participate in one or more cliques. The biological interpretation of this is as yet unclear, but it might indicate that there is a significant chimeric property/LGT between two or more subgroups of isolates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is an interesting property of this clique-based classification. Once a clique is identified then, so long as the genome iteself is not modified (e.g. draft assembly completed), the clique is *permanent*. The addition of new genomes/sequences can only extend the clique, not replace it. Cliques can then be considered as intersecting surfaces, where the clique defines the surface, and individual organisms present in several cliques represent *intersections* between those surfaces. Multiple surfaces may intersect at the same point.\n",
    "\n",
    "For a set of genomes, with a given coverage/identity threshold, the difference between the number of nodes, and the total size of cliques, is reflective of the number of intersections, and may inidicate recombination, or that the classification does not fall along *natural boundaries* in the data. This suggests an approach where the total clique size can be inspected as one or more thresholds increases, and fluctuations observed: *minima* on this path indicate natural groupings of the genomes.\n",
    "\n",
    "I may have a mathematical answer for David Baltrus' suggestion of a universal whole genome classification scheme."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions for identification of cliques/subgraphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def count_cliques(graph):\n",
    "    cliques = list(nx.find_cliques(graph))\n",
    "    clique_size = sum([len(c) for c in cliques])\n",
    "    subgraphs = list(nx.connected_component_subgraphs(graph))\n",
    "    return(len(graph), len(subgraphs), len(cliques), clique_size)\n",
    "\n",
    "def print_cliques(graph):\n",
    "    cliques = list(nx.find_cliques(graph))\n",
    "    print(\"Network size: {0}, Subgraphs: {1}, Number of cliques: {2}, Total clique size: {3}\".format(*count_cliques(graph)))\n",
    "    for c in cliques:\n",
    "        print(\"{0}\\n{1}\\n\\n\".format(len(c),\n",
    "                                    [labeldict[n] if n in labeldict else n\n",
    "                                     for n in c]))\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Increasing thresholds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What happens if we increase the requirement for percentage coverage to be greater than 90% of the total genome length?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create graph\n",
    "H = nx.Graph()\n",
    "\n",
    "# Add nodes, then loop over rows in node data, adding edges\n",
    "for node in node_names:\n",
    "    H.add_node(node)\n",
    "\n",
    "errs = node_data.apply(add_edge, axis=1, args=(H,), cov_thresh=0.9)\n",
    "\n",
    "# Draw network\n",
    "fig, ax = subplots(figsize=(20,20))\n",
    "layout = nx.spring_layout(H, weight=weight, k=0.025, iterations=800)\n",
    "nx.draw(H, pos=layout, ax=ax, with_labels=True, labels=labeldict, alpha=0.4, font_size=10, edge_color=\"#cccccc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the graph, we can see that there is separation into subgraphs that appear to correspond to natural species groupings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print_cliques(H)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspection of the cliques at this threshold however shows that there's quite a bit of confusion within those groupings, that stems from the different edge weights - not all the internal groupings are equally well-connected. \n",
    "\n",
    "What happens if we require that percentage identity also needs to be over 99%?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Remove edges from the network if percentage identity is less than 99%\n",
    "edgelist = H.edges(data='identity')\n",
    "for e in edgelist:\n",
    "    if e[-1] < 0.95:\n",
    "        H.remove_edge(e[0], e[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "draw_network(H, k=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print_cliques(H)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There seems to have been no change. So what if we increase to 99.9% identity threshold?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "edgelist = H.edges(data='identity')\n",
    "for e in edgelist:\n",
    "    if e[-1] < 0.999:\n",
    "        H.remove_edge(e[0], e[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "draw_network(H, k=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print_cliques(H)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There's a great deal of fragmentation of the network - 110 subgraphs, with lots of singletons."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions to check thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def trim_graph(graph, threshold, data='identity'):\n",
    "    edgelist = graph.edges(data=data)\n",
    "    for e in edgelist:\n",
    "        if e[-1] < threshold:\n",
    "            graph.remove_edge(e[0], e[1])\n",
    "    return(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(G.edges())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Change %identity threshold and watch clique size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What happens to the difference between total clique size and network size, as we increase %identity threshold?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create graph\n",
    "J = nx.Graph()\n",
    "\n",
    "# Add nodes, then loop over rows in node data, adding edges\n",
    "for node in node_names:\n",
    "    J.add_node(node)\n",
    "\n",
    "errs = node_data.apply(add_edge, axis=1, args=(J,), cov_thresh=0.5)\n",
    "\n",
    "# Loop over thresholds from 0 to 100% identity, get difference in size\n",
    "# We could increment through the observed thresholds in the graph, but\n",
    "# even for this example, a resolution of 1500 points between 0.85 and\n",
    "# 1 is quicker (though not quick!)\n",
    "thresholds = linspace(0.85, 1, 1500)\n",
    "row_list = []\n",
    "for t in thresholds:\n",
    "    J = trim_graph(J, t)\n",
    "    netsize, sgsize, clqcount, clqsize = count_cliques(J)\n",
    "    datadict = {'identity': t,\n",
    "                'network_size': netsize,\n",
    "                'subgraph_count': sgsize,\n",
    "                'clique_count': clqcount,\n",
    "                'total_clique_size': clqsize,\n",
    "                'difference': clqsize-netsize}\n",
    "    row_list.append(datadict)\n",
    "threshold_profile = pd.DataFrame(row_list, columns=['identity', 'network_size',\n",
    "                                                    'subgraph_count',\n",
    "                                                    'clique_count', 'total_clique_size',\n",
    "                                                    'difference'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the data looks sane\n",
    "threshold_profile.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Excess isolates in cliques\n",
    "\n",
    "The excess of total number of isolates in cliques over the total number of isolates represents the count of isolates that are at *edges* or *intersections* between groups. A large excess indicates a difficulty in classifying those isolates uniquely. An excess of zero (or nearly zero) indicates that each isolate can be placed in exactly one mutually-supporting group, and may represent a natural clustering threshold for the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(threshold_profile['identity'], threshold_profile['difference'])\n",
    "xlim(0.85, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the plot we see three major, and around eight minor peaks. The largest peaks are just short of 90% identity, and around 86% identity. There are smaller peaks at 92, 93 and 96% identity. It is tempting to see the peaks as indicating identity thresholds where there is much classification confusion.\n",
    "\n",
    "It could be that the larger peaks indicate confusion at allocating distinct species or genus boundaries. The smaller peaks indicate confusion at allocating species or 'subspecies' boundaries.\n",
    "\n",
    "There are noticable minima at around 91%, 95% and 98% identity. These may represent natural boundary minima that separate out genus and species well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The first large peak\n",
    "plot(threshold_profile['identity'], threshold_profile['difference'])\n",
    "xlim(0.86, 0.875)\n",
    "ylim(0, 800)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the 0.864 peak:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create graph\n",
    "K = nx.Graph()\n",
    "\n",
    "# Add nodes, then loop over rows in node data, adding edges\n",
    "for node in node_names:\n",
    "    K.add_node(node)\n",
    "\n",
    "errs = node_data.apply(add_edge, axis=1, args=(K,), cov_thresh=0.5)\n",
    "\n",
    "# Trim to 0.864% identity\n",
    "K = trim_graph(K, 0.864)\n",
    "\n",
    "# Draw network\n",
    "draw_network(K, k=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What are the cliques?\n",
    "print_cliques(K)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The graph and list of cliques indicate that the genus-level separation is good, but there are a large number of cliques within those clusters that apparently do not separate well between assigned species - mostly within *Dickeya*.\n",
    "\n",
    "Moving up to the next minimum, at about 0.868:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Trim to 0.868% identity\n",
    "K = trim_graph(K, 0.868)\n",
    "\n",
    "# Draw network\n",
    "draw_network(K, k=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# What are the cliques?\n",
    "print_cliques(K)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now there are fewer cliques, especially for *Dickeya*, which appears to have settled out at a *Dch/Dze*:other *Dickeya* split, with some lingering connecting edges - apparent both from the graph and the clique list.\n",
    "\n",
    "The really big peak is at around 0.893% identity, with the next minimum at around 0.914%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The largest peak\n",
    "plot(threshold_profile['identity'], threshold_profile['difference'])\n",
    "xlim(0.896, 0.92)\n",
    "ylim(0, 2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Trim to 0.896% identity\n",
    "K = trim_graph(K, 0.8966)\n",
    "\n",
    "# Draw network\n",
    "draw_network(K, k=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What are the cliques?\n",
    "print_cliques(K)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the large peak, we seem to have hit a threshold of indecision for *Pectobacterium* spp. - which seem to take up most of the overlapping cliques. *P. wasabiae* looks to be well split-off from the the other *Pectobacteria*, but there's quite a bit of confusion among the other species.\n",
    "\n",
    "At the next minimum:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Trim to 0.914% identity\n",
    "K = trim_graph(K, 0.914)\n",
    "\n",
    "# Draw network\n",
    "draw_network(K, k=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What are the cliques?\n",
    "print_cliques(K)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is only a small amount of confusion - the isolates are well-separated into groups, but not in a way that matches the assigned species names (for the most part). Some species are well separated into cliques, such as:\n",
    "\n",
    "* *P. carotovorum*\n",
    "* *E. amylovora*\n",
    "* *D. zeae*\n",
    "* *P. wasabiae*\n",
    "* *D. chrysanthemi*\n",
    "* *D. paradisiaca*\n",
    "\n",
    "but, at this point, most *Dickeya* spp. are still lumped together, and there's not clear disconnection between *P. betavasculorum* and *P. atrosepticum*.\n",
    "\n",
    "Moving on to one of the later peaks, at 93.4% identity, with corresponding minimum at 0.955:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A species boundary peak?\n",
    "plot(threshold_profile['identity'], threshold_profile['difference'])\n",
    "xlim(0.93, 0.96)\n",
    "ylim(0, 350)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Trim to 0.934 identity\n",
    "K = trim_graph(K, 0.934)\n",
    "\n",
    "# Draw network\n",
    "draw_network(K, k=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What are the cliques?\n",
    "print_cliques(K)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We still have the large genus-level groupings, but now there are several points of confusion within the *P. carotovorum* cluster, leading to several cliques with overlapping membership. \n",
    "\n",
    "As we approach the minimum at 0.955:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Trim to 0.955 identity\n",
    "K = trim_graph(K, 0.955)\n",
    "\n",
    "# Draw network\n",
    "draw_network(K, k=0.025)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What are the cliques?\n",
    "print_cliques(K)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a 'perfect' assignment of isolates to cliques/subgraphs, that has split the *P. carotovorum* subgroup into five distinct mutually-supporting cliques. \n",
    "\n",
    "We can look at the individual subgraphs, below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Get subgraphs\n",
    "subgraphs = list(nx.connected_component_subgraphs(K))\n",
    "\n",
    "# Draw a single subgraph\n",
    "draw_network(subgraphs[2], figsize=(10, 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clique count and subgraph count\n",
    "\n",
    "Plotting the variation in clique count (as opposed to total clique members) with percentage identity, a clear trend is notable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(threshold_profile['identity'], threshold_profile['clique_count'])\n",
    "xlim(0.85, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a similar 'spiky' plot to the total number of clique members, but overlaid on a baseline that increases gradually at first (up to about 97% identity), and then rapidly from that point.\n",
    "\n",
    "This baseline is, essentially, the subgraph count. As cliques cannot span subgraphs, there must be at least as many cliques as subgraphs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(threshold_profile['identity'], threshold_profile['subgraph_count'])\n",
    "xlim(0.85, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Subtracting the subgraph count from the clique count, we get the following profile:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(threshold_profile['identity'], threshold_profile['clique_count']-threshold_profile['subgraph_count'])\n",
    "xlim(0.85, 1)\n",
    "xlabel(\"%identity\")\n",
    "ylabel(\"confused cluster members\")\n",
    "title(\"Cluster confusion\")\n",
    "savefig(\"/Users/lpritc/Desktop/thresholds.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This gives us a second way to identify natural boundaries in the data: where do the number of cliques match the number of subgraphs? That is, at which points does the plot above touch the *x*-axis? At these points, we might think that the choice of thresholds has found natural groupings of data.\n",
    "\n",
    "We can estimate such points by plotting a histogram of zero values in any window, and noting the locations of the peaks. As a future improvement, it should be possible to identify locations of zeros with confidence intervals, in an automated manner, by statistical inference from the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bounds = threshold_profile.loc[threshold_profile['clique_count']-threshold_profile['subgraph_count']==0,]\n",
    "n, bins, patches = hist(bounds['identity'], bins=50, normed=True)\n",
    "xlim(0.85, 1)\n",
    "xlabel('%identity')\n",
    "ylabel('frequency')\n",
    "title('Natural clusterings')\n",
    "savefig(\"/Users/lpritc/Desktop/threshold_zeros.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bounds = threshold_profile.loc[threshold_profile['clique_count']-threshold_profile['subgraph_count']==0,]\n",
    "sns.kdeplot(bounds['identity'],\n",
    "            bw=0.05, shade=True, legend=False, gridsize=1000)\n",
    "xlim(0.85, 1)\n",
    "xlabel('%identity')\n",
    "title('Natural clusterings')\n",
    "savefig(\"/Users/lpritc/Desktop/threshold_zeros_kde.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(sns.kdeplot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This indicates that the regions of percentage identity at 0.850-0.855; 0.950-0.955; 0.965-0.970; 0.990-0.995 are likely to be natural boundaries.\n",
    "\n",
    "We can inspect these, below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create graph\n",
    "L = nx.Graph()\n",
    "\n",
    "# Add nodes, then loop over rows in node data, adding edges\n",
    "for node in node_names:\n",
    "    L.add_node(node)\n",
    "\n",
    "errs = node_data.apply(add_edge, axis=1, args=(L,), cov_thresh=0.5)\n",
    "\n",
    "# Trim to 0.855% identity\n",
    "L = trim_graph(L, 0.855)\n",
    "\n",
    "# Draw network\n",
    "draw_network(L, k=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print_cliques(L)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this level of identity, we have a split into the major genus groups - with some of the smaller clusters of isolates and individual isolates also indicated as groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Trim to 0.955% identity\n",
    "L = trim_graph(L, 0.955)\n",
    "\n",
    "# Draw network\n",
    "draw_network(L, k=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_cliques(L)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This level of classification closely matches the individual species as previously assigned (some necessary reclassification notwithstanding). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Trim to 0.969% identity\n",
    "L = trim_graph(L, 0.969)\n",
    "\n",
    "# Draw network\n",
    "draw_network(L, k=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_cliques(L)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this more restrictive level of identity, *P. carotovorum* has been divided into 11 groupings, and other 'traditional' species-level classifications have been subdivided also (especially within *Dickeya*) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Trim to 0.9945% identity\n",
    "L = trim_graph(L, 0.9945)\n",
    "\n",
    "# Draw network\n",
    "draw_network(L, k=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_cliques(L)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, the number of cliques/subgraphs has doubled, and many isolates have been separated into single-member subgraphs. It is tempting to interpret this as being *too* fine a distinction between genomes for useful classification, but it does help highlight 'near-clonal' isolates, whose genomes are highly similar (e.g. *E. amylovora* and *D. solani*)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this dataset, it appears that there are natural 'genus', 'species' and 'subspecies' boundaries that fall out of the data - more boundaries with different meanings may be found in more complex datasets. Rather than looking at these measures across many cross-genera isolates, it may be worth considering following the boundary analyses progressively, only within connected subgraphs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining genomotypes at natural boundaries\n",
    "\n",
    "As shorthand, we'll refer to the main peaks/identity boundaries as follows:\n",
    "\n",
    "* genus: 0.855\n",
    "* species: 0.955\n",
    "* subspecies: 0.969\n",
    "* clonal: 0.9945\n",
    "\n",
    "At each of these boundaries, we'll identify and label genomotype groupings to be the subgroups/cliques found at those thresholds."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions to find and plot genomotypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_genomotypes(node_names, node_data, threshold):\n",
    "    # Create graph\n",
    "    G = nx.Graph()\n",
    "\n",
    "    # Add nodes and edges\n",
    "    for node in node_names:\n",
    "        G.add_node(node)\n",
    "    errs = node_data.apply(add_edge, axis=1, args=(G,), cov_thresh=0.5)\n",
    "\n",
    "    # Trim edges to the passed threshold and get clique/subgraph info\n",
    "    G = trim_graph(G, threshold)\n",
    "    cliques = list(nx.find_cliques(G))\n",
    "    clique_size = sum([len(c) for c in cliques])\n",
    "    subgraphs = list(nx.connected_component_subgraphs(G))\n",
    "    \n",
    "    # Sanity check that we're at a real boundary\n",
    "    assert clique_size == len(G), \"Clique size does not match network size\"\n",
    "    assert len(subgraphs) == len(cliques), \"Number of subgraphs and cliques differ\"\n",
    "\n",
    "    # As the cliques and subgraphs are the same, we return the subgraphs:\n",
    "    return(subgraphs)\n",
    "\n",
    "def plot_graphs(graph_list, cols=5, weight='identity', k=0.1, iterations=800, labels=labels):\n",
    "    rows = len(graph_list)/cols + 1\n",
    "    fig = figure(figsize=(cols * 5, rows * 5))\n",
    "    for idx, G in enumerate(graph_list):\n",
    "        ax = fig.add_subplot(rows, cols, idx + 1)\n",
    "        layout = nx.spring_layout(G, weight=weight, k=k, iterations=iterations)\n",
    "        labels = {key: val for (key, val) in labeldict.items()\n",
    "                  if key in G.nodes()}\n",
    "        nx.draw(G, pos=layout, ax=ax, with_labels=True, labels=labels,\n",
    "                alpha=0.4, font_size=6, edge_color=\"#cccccc\")\n",
    "        title(\"Genomotype {0}\".format(idx + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Streptomyces only\n",
    "# Three bounds: 0.965772, 0.978859, 1.000\n",
    "#species = find_genomotypes(node_names, node_data, 0.966)\n",
    "#plot_graphs(species, labels=labeldict, k=0.7, cols=20)\n",
    "#savefig(\"/Users/lpritc/Desktop/genomotype_species.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Streptomyces only\n",
    "#subspecies = find_genomotypes(node_names, node_data, 0.9788)\n",
    "#plot_graphs(subspecies, labels=labeldict, k=0.7, cols=20)\n",
    "#savefig(\"/Users/lpritc/Desktop/genomotype_subspecies.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Find genomotypes at 'genus' cutoff\n",
    "genus = find_genomotypes(node_names, node_data, 0.855)\n",
    "plot_graphs(genus, labels=labeldict, k=0.7)\n",
    "savefig(\"/Users/lpritc/Desktop/{0}_genomotype_genus.pdf\".format(prefix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Find genomotypes at 'species' cutoff\n",
    "species = find_genomotypes(node_names, node_data, 0.955)\n",
    "plot_graphs(species, labels=labeldict, k=0.7, cols=8)\n",
    "savefig(\"/Users/lpritc/Desktop/{0}_genomotype_species.pdf\".format(prefix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Find genomotypes at 'subspecies' cutoff\n",
    "subspecies = find_genomotypes(node_names, node_data, 0.969)\n",
    "plot_graphs(subspecies, labels=labeldict, k=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Find genomotypes at 'clonal' cutoff\n",
    "clonal = find_genomotypes(node_names, node_data, 0.9945)\n",
    "plot_graphs(clonal, labels=labeldict, k=0.7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Illustrating reclassification/renaming\n",
    "\n",
    "I'd like to produce a Sankey/river plot showing how (I think) the renaming/reclassification of SRE genomes should go, on the basis of the above phenotypes. There's no good way to do this in Python that I'm aware of, so I'm going to create a data table that can be imported into R for rendering with GoogleVis.\n",
    "\n",
    "Essentially, I need to define a graph, with from/to nodes describing classifications, and a weight that corresponds to the number of genomes going from one classification to the other.\n",
    "\n",
    "There could be seven columns in the Sankey diagram, the first three representing:\n",
    "\n",
    "* 'traditional' species: *E. carotovora* or *E. chrysanthemi*\n",
    "* 2003-ish classification: *Pectobacterium* spp.\n",
    "* 2009-ish classification: *Pectobacterium* and *Dickeya*, with Pcc/Pcb subspecies classifications\n",
    "\n",
    "These will be the 'traditional' classes - inferred in part from the `classes.txt` file, and otherwise worked back figuratively from that point (e.g. all 2009 *Pcb*/*Pcc* came from 2003 *P. carotovorum*).\n",
    "\n",
    "The next four columns would be:\n",
    "\n",
    "* 'genus' genomotype\n",
    "* 'species' genomotype\n",
    "* 'subspecies' genomotype\n",
    "* 'clonal' genomotype\n",
    "\n",
    "To demonstrate the various aspects of reclassification, it might be better to show multiple figures - two at most for the presentation: 'genus' and 'species'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, for each of the genomes, we work back from the node name to the contents of `classes.txt` to get the 2009 classification, as the `from` column, and use the genomotype ID from `genus` and `species` classifications, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_genomotype_table(node_names, classdict, genomotypes, prefix=''):\n",
    "    # Identify genomotypes for each isolate\n",
    "    gtdict = {}\n",
    "    for idx, gt in enumerate(genomotypes):\n",
    "        for label in gt:\n",
    "            gtdict[label] = \"Genomotype {1} {0}\".format(idx + 1, prefix)\n",
    "            \n",
    "    # Count transfers from class to genomotype\n",
    "    datadict = {}\n",
    "    for n in node_names:\n",
    "        f, t = classdict[n], gtdict[n]\n",
    "        datadict[(f, t)] = datadict.setdefault((f, t), 0) + 1 \n",
    "        \n",
    "    # Build and return dataframe\n",
    "    row_list = []\n",
    "    for k, v in datadict.items():\n",
    "        dd = {'from': k[0],\n",
    "              'to': k[1],\n",
    "              'weight': v}\n",
    "        row_list.append(dd)\n",
    "    df = pd.DataFrame(row_list, columns=['from', 'to', 'weight'])\n",
    "    return(df, gtdict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Write species dataframe\n",
    "sdf, spdict = make_genomotype_table(node_names, classdict, species, prefix=\"'species'\")\n",
    "sdf.to_csv(os.path.join(indir, 'species_sankey.csv'), index=False)\n",
    "\n",
    "# Write genus dataframe\n",
    "genusdict = {k: v.split()[0] for (k, v) in classdict.items()}\n",
    "gdf, gdict = make_genomotype_table(node_names, genusdict, genus, prefix=\"'genus'\")\n",
    "gdf.to_csv(os.path.join(indir, 'genus_sankey.csv'), index=False)\n",
    "\n",
    "# Make genus dataframe with original class data: genus/class\n",
    "gcdf, gcdict = make_genomotype_table(node_names, classdict, genus, prefix=\"'genus'\")\n",
    "gcdf.columns = ['to', 'from', 'weight']  # Reverse from and to\n",
    "\n",
    "# Stack genus/class and species dataframes\n",
    "df = pd.concat([gdf, gcdf, sdf])\n",
    "df.to_csv(os.path.join(indir, 'genus_class_species.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(node_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyani import pyani_classify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "unconfused = list(pyani_classify.unconfused_graphs(G))\n",
    "len(unconfused)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ug in unconfused:\n",
    "    print(ug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly\n",
    "plotly.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plotly.tools.set_credentials_file(username='widdowquinn', api_key='ATrKeRQnhXpzUGmEX16G')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.plotly as py\n",
    "\n",
    "import urllib.request, json\n",
    "\n",
    "url = 'https://raw.githubusercontent.com/plotly/plotly.js/master/test/image/mocks/sankey_energy.json'\n",
    "response = urllib.request.urlopen(url)\n",
    "data = json.loads(response.read())\n",
    "\n",
    "data_trace = dict(\n",
    "    type='sankey',\n",
    "    width = 1118,\n",
    "    height = 772,\n",
    "    domain = dict(\n",
    "      x =  [0,1],\n",
    "      y =  [0,1]\n",
    "    ),\n",
    "    orientation = \"h\",\n",
    "    valueformat = \".0f\",\n",
    "    valuesuffix = \"TWh\",\n",
    "    node = dict(\n",
    "      pad = 15,\n",
    "      thickness = 15,\n",
    "      line = dict(\n",
    "        color = \"black\",\n",
    "        width = 0.5\n",
    "      ),\n",
    "      label =  data['data'][0]['node']['label'],\n",
    "      color =  data['data'][0]['node']['color']\n",
    "    ),\n",
    "    link = dict(\n",
    "      source =  data['data'][0]['link']['source'],\n",
    "      target =  data['data'][0]['link']['target'],\n",
    "      value =  data['data'][0]['link']['value'],\n",
    "      label =  data['data'][0]['link']['label']\n",
    "  ))\n",
    "\n",
    "layout =  dict(\n",
    "    title = \"Energy forecast for 2050<br>Source: Department of Energy & Climate Change, \" +\n",
    "            \"Tom Counsell via <a href='https://bost.ocks.org/mike/sankey/'>Mike Bostock</a>\",\n",
    "    font = dict(\n",
    "      size = 10\n",
    "    )\n",
    ")\n",
    "\n",
    "fig = dict(data=[data_trace], layout=layout)\n",
    "py.iplot(fig, validate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotly.offline.plot(fig, validate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotly.offline.init_notebook_mode(connected=False)\n",
    "plotly.offline.iplot(fig, validate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(plotly.offline.init_notebook_mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(plotly.offline.offline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "links = pd.DataFrame(data['data'][0]['link'])\n",
    "links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
